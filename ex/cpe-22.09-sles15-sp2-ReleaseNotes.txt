HPE Cray Programming Environment 22.09 Release Notes
====================================================

HPE Cray Compiling Environment (CCE) 14.0.3
==============================================

Release Date:
-------------
September 2022

Purpose:
--------
CCE 14.0.3 provides Fortran, C, and C++ compilers for Cray XC and CS systems, 
HPE Cray supercomputer systems, HPE Apollo 2000 Gen10Plus systems, and HPE Apollo 80 systems. 

Key Changes and Support with CCE 14.0.3:
-------------------------------------------
CCE 14.0.3:
- Bug Fixes
- SVE support (beta)

------------
CCE 14.0.2:
- Bug Fixes
- AMD ROCm 5.2 support
- Support for generating native GPU floating-point atomic add instructions for "omp atomic"
  constructs
- Support for the "-m[no-]unsafe-fp-atomics" compiler flag (C, C++, and Fortran) for
  controlling native floating-point atomic generation on AMD MI250X GPUs

------------
CCE 14.0.1:
- Bug Fixes

------------
CCE 14.0.0:
- LLVM 14 base
- C++17 support
  - Note: libstdc++ (and associated C++ library headers) updated from GCC 8.1.0
    to 10.3.0. Recommend C++ objects be recompiled to avoid ABI incompatibilities.
- SVE support (beta)
- AMD ROCm 5.0 and 5.1 support
- Tuned Fortran AMDGPU loop unrolling heuristic
- Optimized OpenMP "device scope" atomics/fences
- Complete support for AddressSanitizer, ThreadSanitizer (incl. Archer) for
  C/C++ programs (CPU only), enabled using the command line option

    -fsanitize=address|thread

- Preliminary support for AddressSanitizer, ThreadSanitizer (incl. Archer)
  for Fortran programs (CPU only), enabled using the command line option

    -fsanitize=address|thread

  Note that:
    - The option -g is required for AddressSanitizer
    - COMMON variables are not supported by AddressSanitizer currently

- Optimized OpenMP offload kernel launch performance
- CCE supports partial OpenMP 5.0. The following OpenMP 5.0 features
  have been added in this release for Fortran, C, and C++, unless noted otherwise.
  - task reductions (Fortran)
  - simd if (Fortran)
  - "requires unified_shared_memory" for AMD MI250X (Fortran)
- CCE supports partial OpenACC 2.6 and 3.0. The following OpenACC features
  have been added in this release for Fortran.
  - "if_present" clause on "update"
  - "acc_attach" and "acc_attach_async" APIs
  - "async" and "wait" on "acc data"
  - "if" clause on "acc wait"

User and Application Impact:
---------------------------
C++ applications built using CCE 13 or earlier may need to be recompiled due to the significant
changes that were necessary to implement C++17.  This is expected to be a one-time requirement.

Some non-standard Cray Fortran extensions supporting shorthand notation for logical operations
will be removed in a future release.  CCE 14 will issue warning messages when these are
encountered, providing time to adapt the application to use standard Fortran.  

Issues or Bugs Resolved:
------------------------
CCE 14.0.3:
-----------
CAST-29777 Cray Fortan Compiler Issue
CAST-30430 Cray Fortran compiler segfault in optcg compiling xRage
CAST-30294 (OLCFDEV-1002) Crusher CCE+Fortran+OpenMP ExaStar/thornado internal compiler error w/ -O3 (IPA ASSERT)
CAST-27060 OLCFDEV-262: Cray Fortran Compiler: ICE When Compiling OpenMP  teams distribute parallel do
CAST-30199 use of maxval with dim causes omp target ftn compiler error
CAST-30279 (OLCFDEV-992) Fortran incorrect answers when optimizing do loops
CAST-28200 Internal Compiler Error on type declaration with cce Fortran

CCE 14.0.2:
-----------
CAST-30368 cce 14.0.1 Fortran crashes with current working directory above a certain length
CAST-30181 A compiler regression in Cray Fortran BIND(C) has been found in cce/14
CAST-30038 OLCFDEV-935 - CCE 14 Fortran OpenMP Metadirective Bogus Error Message Statements Between Directive and DO
CAST-29999 (OLCFDEV - 838) CCE Fortran OpenMP Metadirective with Collapse clause Issue
CAST-29974 Cray compiler support for scalar variables in target region
CAST-29916 Error in `/opt/cray/pe/cce/12.0.3/cce/x86_64/bin/ftnfe': munmap_chunk(): invalid pointer: 0x00007f6cf8240010
CAST-29889 Navy narwhal: Users fortran code causes CCE to segfault - Elevation of case 5363548947
CAST-29706 CCE - ENDASSOCIATE not accepted in FREE FORMAT.
CAST-29705 CCE - ENDENUM (without space) is not accepted in FREE format. This is legal
CAST-26211 ICE "Invalid expression type" pdgcs/v_acc_util.c, line 3240
CAST-24430 CCE Fortran MAXLOC intrinsic is slow compared to Intel
CAST-24233 crayftn internal compiler error on allocate statement with invalid syntax

CCE 14.0.1:
-----------
CAST-29778 FTN Compiler seems not to support a valid Fortran construct in an OpenMP offload context ..
CAST-28223 OLCFDEV-378: CCE Fortran Bogus Error Message with Stop statement in OpenMP Declare Target
CAST-22748 Cray Fortran allows RECL specifier on OPEN with ACCESS=STREAM
CAST-29303 (OLCFDEV-643) CCE+Fortran+OpenMP Compiler Error
CAST-26853 (OLCFDEV-209) Linking OpenMP offload with global const variable gives "symbol multiply defined" with Cray compiler
CAST-27129 (OLCFDEV-276) CCE Fortran Link Error with OpenMP Offload (gtsim)
CAST-28065 CRAY_ACC_ERROR -  cuStreamSynchronize returned CUDA_ERROR_ILLEGAL_ADDRESS for COSMO code
CAST-28156 Different behavior of Fortran RESHAPE with cce vs GNU or Intel
CAST-25161 CCE Fortran generates 2 stores for conditional update of array in vector loop (rome)
CAST-22727 Cray Fortran does not return error from RESHAPE when SOURCE is short

CCE 14.0.0:
-----------
CAST-28909 Excessively long Fortran compile times
CAST-28805 Navy-narwhal: CCE Fortran ICE (inline issue) when trying to compile WRFDM
CAST-29354 Cray Fortran compiler is_contiguous function returns incorrect result
CAST-29249 Cray Fortran compiler hangs with O2 optimization
CAST-29004 CCE v13.x fails to build ncurses via Spack
CAST-28920 Excessively long Fortran compile times
CAST-29124 Problem with inlining routine with an OpenACC kernel
CAST-25673 Curious behavior with negative stop-code using CCE Fortran 10.0.3
CAST-25678 RFE: Add compiler option -fopenmp-simd
CAST-27262 CCE does not support std::reduce
CAST-25896 Using upc_memput on a single node is very slow
CAST-27066 Variable is used before it is defined warning on loop index variables
CAST-27636 CCE Fortran OpenMP Offload Array Reduction Gives Linking Error
CAST-27692 CCE Fortran OpenMP offload Error Declare Target Private Var
CAST-27188 CCE Compiler ICE with OpenMP offloading array reduction
CAST-26788 FTN OPTCG goes into an infinite loop trying to compile a file
CAST-28854 cce compile error for Kokkos app
CAST-28621 CCE Fortran OpenMP Wrong Results with Metadirective User Selector in Default Clause
CAST-29502 Segfault and CRAY_ACC_ERROR in UMT OMP Target "map to" clause
CAST-29105 CCE Fortran: Answer wrong when compiler optimization enabled
CAST-25161 CCE Fortran generates 2 stores for a conditional update of the array in vector loop (rome)
CAST-28065 CRAY_ACC_ERROR -  cuStreamSynchronize returned CUDA_ERROR_ILLEGAL_ADDRESS for COSMO code
CAST-23376 Would like a vector version of certain Fortran intrinsics, particularly for ARM SVE systems
CAST-22727 Cray Fortran does not return an error from RESHAPE when SOURCE is short

Product and OS Dependencies:
----------------------------
  This CCE release is supported on
    - Cray XC systems running CLE 7.0 UP03 
    - Cray CS systems running RedHat 8
    - HPE Cray supercomputer systems running CSM with COS 2.1.X (SLES15 SP2) or COS 2.2.X (SLES15 SP3)
    - HPE Cray supercomputer systems running HPCM with SLES15 SP2 or SLES15 SP3
    - HPE Cray supercomputer systems running HPCM with RHEL 8.4 
    - HPE Apollo 2000 Gen10Plus systems running RedHat 8
    - HPE Apollo 80 systems running RedHat 8

  AMD GPU offloading support requires at least ROCm 5.0

Notes and Limitations:
----------------------
  None

Documentation:
--------------
  - S-5212 Cray Compiling Environment Release Overview (13.0)
  - S-3901 Cray Fortran Reference Manual
  - S-2179 Cray C and C++ Quick Reference
  - Basic man pages: crayftn(1), craycc(1), crayCC(1), intro_openmp()
  - Please see https://clang.llvm.org/docs/UsersManual.html or use the -help command line
    option for more information on using Clang

Modulefile:
-----------
The following will load the modules necessary to use CCE:
  module load PrgEnv-cray

The following will switch to x.y.z version of CCE:
  module swap cce cce/x.y.z 

Installation instructions:
--------------------------
  rpm -ivh cce-14.0.3-202208160138.9910ff1670792-2.sles15sp2.x86_64.rpm.x86_64.rpm

  The following script will set CCE version 14.0.3 default:
  /opt/cray/pe/admin-pe/set_default_files/set_default_cce_14.0.3

License:
--------
  Except for the third party components and software licensed by HPE through proprietary
  agreements, components, files or programs contained within this package or product are
  Copyright -2022 Hewlett Packard Enterprise Development LP. 

  Attribution notices for open source licensed software for this package are detailed
  in the file:

  /opt/cray/pe/cce/14.0.1/ATTRIBUTIONS_14.0.txt

Craypkg-gen 1.3.26
==============

Release date
------------
   September 2022

Purpose
-------
   Bug fix release.

Bugs fixed in this release
--------------------------
   - Remove conflicts nvhpc module has against nvidia module
   - Add CUDA header files to CPATH in nvhpc modulefile

Dependencies
------------
   The craypkg-gen 1.3.26 release is supported on the following HPE
   Cray systems:
   - Cray XC/XE/XK systems with CLE version 5.2 or later.
   - Cray EX systems SLE 15.0 or later and RHEL 8.0 or later.

   Driver support for integrating Third Party C, C++, and Fortran libraries
   through .pc files using pkg-config is used in CrayPE 2.x and later.


Limitation
----------
   - Library dependencies for static libraries are not added to the .pc files
       for keywords Requires.private and Libs.private. A warning is issued by
       the craypkg-gen tool to advise users to add this information to the
       libraries .pc files.
   - RPM limits packages to 4GB

Documentation
-------------
   Man pages for craypkg-gen are found by executing `module load craypkg-gen`
   and then `man craypkg-gen`. See
   http://www.freedesktop.org/wiki/Software/pkg-config for a pkg-config
   introduction.

   Examples for creating modulefiles for Intel, PGI and Python are included in
   the craypkg-gen ‘doc’ directory:

    /opt/cray/craypkg-gen/1.3.26/doc/intel_example.txt
    /opt/cray/craypkg-gen/1.3.26/doc/pgi_example.txt
    /opt/cray/craypkg-gen/1.3.26/doc/python_example.txt

Example:

   - As an example, the Intel 16.0.3.210 compiler was recently released.
     After installing the compiler the administrator creates a modulefile for
     this release by executing the following commands:

         # module load craypkg-gen
         # craypkg-gen -m /opt/intel/compilers_and_libraries_2016.3.210

     This version of the Intel compiler is made default by executing the
     command:

         # /opt/admin-pe/set_default_craypkg/set_default_intel_16.0.3.210

Installation instructions
-------------------------

    rpm -ivh craypkg-gen-1.3.26-*-1.sles15sp2.202208162204.b05a71569eea9.x86_64.rpm

   To change the product version to default after installation:

    /opt/cray/pe/admin-pe/set_default_files/set_default_craypkg-gen_1.3.26

Product description
-------------------

   The craypkg-gen 1.3.26 utility provides the system administrator
   a tool to integrate third party software with the Cray software stack.
   Craypkg-gen assists with integration by creating .pc files for C, C++, and
   Fortran libraries, pkg-config enabled modulefiles and RPMs.

   The workflow for using craypkg-gen is
   1) Build the open source software
   2) Create .pc files for libraries
   3) Create pkg-config enabled modulefiles
   4) Customize pkg-config and modulefiles if needed
   5) Package rpms
   6) Install the rpms on the Cray system

Certain components, files or programs contained within this package or product
are Copyright 2013-2022 Hewlett Packard Enterprise Development LP.

Cray Common Tools Interface (CTI) 2.15.14:
======================================

Release Date:
--------------
  August 2022


Product Description:
--------------------
  Cray Common Tools Interface (CTI) is a library that abstracts debugger
  tool support to a common interface regardless of the underlying work
  load manager. It facilitates the staging of files and the launch of
  tool daemons on the compute nodes associated with a parallel job.
  Options and interfaces can be found in the cti(1) and cti(3) manpages.

Changelog:
---------

=======================================================================
## [2.15.14] - 2022-08-03 (22.09)
=======================================================================
 
### Bug Fixes
 
* CTI Frontend daemon conflicting with Dyninst breakpoints  
 
=======================================================================
## [2.15.13] - 2022-07-07 (22.08)
=======================================================================
 
### Bug Fixes
 
* Capture srun stderr output during launch  
* Default to HSN interface for HPCM PALS and HPCM Slurm  
* Copy environment to back end in generic/ssh implementation  
 
### Features
 
* Add Slurm multi-cluster / allocation detection  
* Switch to HPCM PALS highspeed network  
* Added support for rhel86 x86 - PE-41140 
 
=======================================================================
## [2.15.12] - 2022-05-06 (22.06)
=======================================================================
 
### Bug Fixes
 
* Resolve ordering issues with HPCM PALS backend  
* Ending main loop from signal handler in daemon will also end in-progress MPIR launch  
 
### Features
 
* Added support for sles15sp4 x86 - PE-39146 #423  
* Added autogen changelog/release notes functionality - PE-40699 #421  
 
=======================================================================
## [2.15.11] - 2022-04-14 (22.05)
=======================================================================
 
### Bug Fixes
 
* PALS implementation's getApid function - PE-40533  
* Re-add CTI manpages to RPM  
 
### Features
 
* Update release notes  
* Added sles15sp1 aarch64 jenkinsfile - PE-36379 #418  
* Added support for rhel85 x86 - PE-40102 
 
 
=======================================================================
## [2.15.10] - 2022-03-21   (22.04)
=======================================================================

* Update Shasta PALS implementation to use PALS utilities and deprecate
  the previous Shasta PALS API
* Update the HPCM PALS implementations to use PALS utilities

  This release fixes the following bugs:
* Fix the usage of the `aprun` launcher with HPCM PALS instead of
  the default `mpiexec` launcher
* Fix HPCM PALS backend startup when node hostnames are in xname format

=======================================================================
## [2.15.9] - 2022-01-21   (22.02)
=======================================================================

* Default Shasta PALS node count in job launches to 1
* Include `--overlap` in Slurm tool daemon launches for Slurm versions
  20.11 and above

=======================================================================
## [2.15.8] - 2021-12-01   (21.12)
=======================================================================

* Added user documentation manpage cti(1), and developer
  documentation manpage cti(3).
* Preliminary support for the Flux workload manager.
  Note that passwordless SSH access to compute nodes must be
  configured for Flux support. This limitation will be
  removed in a future release.
* Flux, Shasta PALS, and ALPS support can be disabled at
  compile-time if development headers are not available.
* Updated gen compilers to cray-gcc-10.3.0

=======================================================================
## [2.15.7] - 2021-10-21   (21.11)
=======================================================================

* Fix potential deadlock during job launch / attach for HPCM PALS systems,
  as well as the generic SSH interface
* Fix Slurm job attach when running on compute node where hostname does
  not match the Slurm node name
* Add environment variable CTI_SLURM_DAEMON_GRES to set the --gres
  for Slurm daemon launches. For Slurm versions 21.08 and newer, this
  should be set to an empty string (see SchedMD bug)
  https://bugs.schedmd.com/show_bug.cgi?id=12642


Product and OS Dependencies:
-----------------------------
  The Cray CTI 2.15.14 release is supported on the following Cray systems:
    - HPE/Cray XC systems with CLE 7.0 or later
    - HPE/Cray CS systems with CentOS/RH 8.4 or later
    - HPE/Cray Shasta systems with SLES 15 service pack 2 or later
    - HPE Apollo systems with Slurm and RH 8.4 or later
    - Baymax systems with RH 8.4 or later

  Product Dependencies:
    - Cray cray-cdst-support rpm installed

Documentation:
---------------
Currently the only documentation available is found in
common_tools_fe.h, common_tools_be.h, and the tests in the 'tests'
directory.

Installation instructions:
--------------------------

   Installation instructions for .sles15sp2.x86_64:
   =============================================
      rpm -ivh cray-cti-2.15.14-7.sles15sp2.x86_64.rpm

      To make cti 2.15.14 the default version of cray-cti, execute:
      /opt/cray/admin-pe/set_default_files/set_default_cray-cti-2.15.14


 Certain components, files or programs contained within this package or
 product are Copyright 2010-2022 Hewlett Packard Enterprise Development LP.

gcc 12.1.0
=========

Release Date:
-------------
August 2022

Purpose:
--------
The gcc 12.1.0 release.

Product and OS Dependencies:
----------------------------
The gcc 12.1.0 release is supported on
- Cray XC systems running CLE 7.0
- Cray Shasta systems
- HPE Apollo systems running RedHat 8

Documentation:
--------------
http://gcc.gnu.org/gcc-12

Modulefile:
---------------------
module load gcc/12.1.0

This modulefile defines the system paths and environment variables
needed to use gcc, g++ and gfortran on Cray systems.  The gcc modulefile
can be swapped for other gcc versions.  This modulefile may be loaded
as a standalone modulefile or as part of the GNU Programming Environment,
PrgEnv-gnu. The CrayPE drivers, cc, CC, and ftn, are recommended for
use with PrgEnv-gnu to generate compilation and link lines.

Installation instructions:
--------------------------
rpm -ihv cpe-gcc-12.1.0-202208101649.1dfb26392197c-09.x86_64.rpm

To change the product version to default after installation:
   /opt/cray/pe/admin-pe/set_default_files/set_default_gcc_12.1.0

Certain components, files or programs contained within this package or product are
Copyright -2022 Hewlett Packard Enterprise Development LP

gdb4hpc 4.14.3:
======================================

Release Date:
--------------
  August 2022


Product Description:
--------------------
  gdb4hpc is a GDB-based parallel debugger used to debug applications compiled with
  CCE, AOCC, GNU, and Intel Fortran, C and C++ compilers. It allows programmers to
  either launch an application or attach to an already running application that
  was launched on the system. Additionally, it provides comparative debugging
  technology that enables programmers to compare data structures between two
  executing applications. Comparative debugging should be used in conjunction
  with the CCDB GUI tool accessed by loading the cray-ccdb module.

  Some features of gdb include:

  * Command line parallel debugger allows for launching/attaching applications.

  * Utilizes process sets to operate on a subset of application ranks.

  * GDB-like feel, also implements a gdbmode to enable a true parallel gdb.

  * GPU debugging is supported for OpenMP 4.0+ GPU directives; OpenMP 5.0 on AMD
      and Nvidia GPU's.

  * Workload manager support via Common Tools Interface (cray-cti).

Changelog:
---------

=======================================================================
## [4.14.3] - 2022-08-03 (22.09)
=======================================================================
 
### Bug Fixes
 
* Prevent launched application from exiting before network is cleaned up 
* Fix segfault after trying to re-launch a procset that doesn't exist 
 
### Features
 
* Add new-ui and set interior-tty 
* Added gdbgui compatibility 
* Emit error message if remote debugger unexpectedly exits 
 
=======================================================================
## [4.14.2] - 2022-07-14 (22.08)
=======================================================================
 
### Bug Fixes
 
* Handle printing enum values 
* Handle breakpoints with multiple locations 
* Allow program stopped at exit
* Print vector.size
* Remove extra blank line from ptype command 
* Fix uncaught exception after SIGINT during launch  
* Update testing Makefile to work around PE-41446 
* Use correct program arguments when re-launching an app with the run command 
* Handle printing fortran structs 
* Hang if gdb initialization fails 
* Removed internal mrnet build - building with external cray-mrnet - PE-41651 
* Correct indices in the difference vector when comparing decomposed fortran arrays 
* Handle array
* Fixed hang when working with very large arrays 
* Improve parsing of templated classes 
* Make functional test cleanup smarter in the case of a test time out 
* Printing of arrays of fortran complex values 
* Handle printing a corrupted vector 
* Printing of unique_ptr  
 
### Features
 
* Handle SIGINT during launch. 
* Print types of pointers; make pointer references more readable 
* Support info cuda, set cuda, show cuda and help cuda 
* Extend the run interface and add documention 
* Frame command only shows program counter with -v option 
* Show feedback during a job launch while using the zmqnet network protocol. 
* Add info args 
* Add local shell command 
* Add getting started guide and tutorial 
 
=======================================================================
## [4.14.1] - 2022-05-19 (22.06)
=======================================================================
 
### Bug Fixes
 
* Assertion script was continuing in halt mode 
* Fix mrnet failure message on exit on PALS 
* Fix launch on PALS with default gdb4hpc internal gdb 
* Error trying to finish outermost frame 
* Launch on some cray-pals systems using --gdb=gdb work-around 
* Implement --non-mpi launch with zmqnet 
* Fix --non-mpi launch on some PALS systems 
* Fix inconsistent results with comparisons over one million elements 
* Fix print for typedef values, null char* and function pointers 
* Fix array comparison for arrays over 1 million elements 
 
### Features
 
* Added support for rhel86 - PE-41140 #476  
* Add ability to re-launch applications with new "run" command, preserving breakpoints between launches 
* Added support for sles15sp4 x86 - PE-40983 
* Added autogen changelog/release notes functionality - PE-40699 #457  
 
=======================================================================
## [4.14.0] - 2022-04-14 (22.05)
=======================================================================
 
### Bug Fixes
 
* Support "array
* Add reference to man cti PE-40399 
* Set up structure for defining gpu tests PE-40398 
* Gdb4hpc is crashing after an interrupted launch 
* Crash during list command 
* Fixed certain functional tests reporting failure despite actually passing on certain machines. 
* Print out char* as string values 
* Print <optimized out> when values are not available. 
 
### Features
 
* Added optional full suite to functional tests allowing tests to be run against every protocol at once. 
* Overhaul Comparative Debugging and Assertion Scripts 
* Added support for rhel85 - PE-40102 
* Add --non-mpi option for launch.   Allows gdb4hpc to find the initial breakpoint without WLM support. 
 
 
=======================================================================
## [4.13.10] - 2022-03-21  (22.04)
=======================================================================
* Fix the identification of nodes with AMD GPU's when launching or
  attaching with the --gpu option
* Improved error detection and reporting for assertion scripts
* Removed extraneous line number reporting when used within ccdb
* Decompositions now work with C/C++ arrays.  The array length
  is inferred from the decomposition.

=======================================================================
## [4.13.9] - 2022-01-21  (22.02)
=======================================================================
* Regarding gen compilers cray-gcc-10.3.0
  NOTE: If you encounter the following error:
  ImportError: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.26' not found 
  Temporary workaround:
  1) export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/gcc/10.3.0/snos/lib64
  or
  2) module load gcc/10.3.0

=======================================================================
## [4.13.8] - 2021-12-06  (21.12)
=======================================================================
* Updated gen compilers to cray-gcc-10.3.0


Product and OS Dependencies:
-----------------------------
  The gdb4hpc 4.14.3 is supported on the following Cray systems:
    - HPE/Cray XC systems with CLE 7.0 or later
    - HPE/Cray CS systems with CentOS/RH 8.4 or later
    - HPE/Cray Shasta systems with SLES 15 service pack 2 or later
    - HPE Apollo systems with Slurm and RH 8.4 or later
    - Baymax systems with RH 8.4 or later

  Product Dependencies:
    - Cray cray-cti rpm installed
    - Cray cray-cdst-support rpm installed

Documentation:
---------------
Type `man gdb4hpc` with the gdb4hpc module loaded to read the gdb4hpc(1) man page.

Simple usage examples are provided at the end.

Also, type `help` at the gdb4hpc command line for more information on commands.

Installation instructions:
--------------------------

   Installation instructions for .sles15sp2.x86_64:
   =============================================
      rpm -ivh gdb4hpc-4.14.3-20220811153241_a7f2329c-3.sles15sp2.x86_64.rpm

      To make gdb4hpc 4.14.3 the default version of gdb4hpc, execute:
      /opt/cray/pe/admin-pe/set_default_files/set_default_gdb4hpc_4.14.3


Certain components, files or programs contained within this package or product are
Copyright  2007-2022 Hewlett Packard Enterprise Development LP.

HDF5 1.12.2.1
=============

Release Date:
-------------
  September 2022

Purpose:
--------
  This HDF5 release contains the following:
  * Update to upstream release 1.12.2
  * Support for the CCE 14 compiler on Cray XC systems

Product and OS Dependencies:
----------------------------
  The HDF5 release is supported on the following systems:
    * Cray EX systems with CLE 7.0 and later
    * Cray XC systems with CLE 7.0 UP03 and later

  The HDF5 1.12.2.1 release requires the following software products:

    * Cray EX systems:
      CrayPE 2.1.2 or later

      One or more compilers:
        CCE 14.0 or later
        GCC 9.0 or later
        Intel 2021.0 or later
        Nvidia 20.7.0 or later
        AOCC 3.0 or later
        ROCm 4.3 or later

    * Cray XC systems:
      Cray MPT 8.0 or later, or cray-mvapich 2.3.2 or later for A64FX-based systems

      One or more compilers:
        CCE 14.0 or later
        GCC 9.0 or later
        Intel 2021.0 or later
        Nvidia 20.7.0 or later

Notes and Limitations:
----------------------
  Users are encouraged to use the Cray compiler scripts (cc, ftn, CC)
  to include the HDF5 header files and link in the HDF5 libraries,
  rather than the HDF5 compiler scripts (h5cc, h5fc, h5c++) included
  in the release.

Documentation:
--------------
  http://www.hdfgroup.org/HDF5/doc/index.html

Modulefile:
-----------
  module load cray-hdf5
  OR
  module load cray-hdf5-parallel

Product description:
--------------------
  HDF5 is a data model, library, and file format for storing and managing data.
  It supports an unlimited variety of datatypes, and is designed for flexible
  and efficient I/O and for high volume and complex data. HDF5 is portable and
  is extensible, allowing applications to evolve in their use of HDF5. The HDF5
  Technology suite includes tools and applications for managing, manipulating,
  viewing, and analyzing data in the HDF5 format.

Installation:
-------------
 Installation instructions for CLE 7.0 and later:
 ================================================
  rpm -ivh cray-hdf5-1.12.2.1-*202208150309.a12717af9a8b7-1.sle15.x86_64.rpm
    The "*" in the install command represents compiler version combinations.

  To make this the default version, execute:
    /opt/cray/pe/admin-pe/set_default_files/set_default_hdf5_1.12.2.1

Certain components, files or programs contained within this package or product
are Copyright 2019-2022 Hewlett Packard Enterprise Development LP.

Cray MPICH 8.1.19:
=======================================

Release Date:
-------------
  August 14, 2022


Purpose:
--------
  Cray MPICH 8.1.19 is based upon ANL MPICH 3.4a2 with support for libfabric
  and is optimized for the Cray Programming Environment.
    
  Major Differences Cray MPICH 8.1.19 from the XC Cray MPICH include:

      - Uses the new ANL MPICH CH4 code path and libfabric for network
        support.

      - Does not support -default64 mode for Fortran

      - Does not support C++ language bindings

  New Cray MPICH features for HPE Cray EX and Apollo systems:

      - Cray MPICH uses the libfabric "verbs;ofi_rxm" provider by default.
        This is the supported and optimized OFI libfabric provider for
        Slingshot-10 and Apollo systems.

      - Cray MPICH offers support for multiple NICs per node. Starting with
        version 8.0.8, by default Cray MPICH will use all available NICs on
        a node. Several rank-to-NIC assignment policies are supported. For
        details on choosing a policy for assigning ranks to NICS, or for
        selecting a subset of available NICs, please see the following
        environment variables documented in the mpi man page.

        MPICH_OFI_NIC_VERBOSE
        MPICH_OFI_NIC_POLICY
        MPICH_OFI_NIC_MAPPING
        MPICH_OFI_NUM_NICS

      - Enhancements to the MPICH_OFI_NIC_POLICY NUMA mode have been added.
        Starting with version 8.0.14, if the user selects the NUMA policy,
        the NIC closest to the rank is selected. A NIC no longer needs to
        reside in the same numa node as the rank. If multiple NICs are
        assigned to the same numa node, the local ranks will round-robin
        between them. Numa distances are analyzed to select the closest NIC.

      - Cray MPICH supports creating a full connection grid during MPI_Init.
        By default, OFI connections between ranks are set up on demand. This
        allows for optimal performance while minimizing memory requirements.
        However, for jobs requiring an all-to-all communication pattern, it
        may be beneficial to create all OFI connections in a coordinated
        manner at startup. See the MPICH_OFI_STARTUP_CONNECT description in
        the mpi man page.

      - Cray MPICH supports runtime switching to the UCX netmod starting
        with version 8.0.14. To do this load the craype-network-ucx module
        and module swap between Cray-MPICH and Cray-MPICH-UCX modules.  For
        more information including relevant environment variables reference
        the intro_mpi man page with the Cray-MPICH-UCX module loaded.

      - Lmod support for HPE Cray EX starting with Cray MPICH 8.0.16.


Key Changes and Bugs Closed:
----------------------------
  Changes in Cray MPICH 8.1.19

      - CAST-29720 - Fix truncated MPICH_DIR path in cray-mpich-abi module
      - CAST-29872 - MPI-IO: Fix a Lustre PFL component offset translation error in collective write and read.
      - CAST-30088 - MPI-IO: Fix the read-bytes in status of collective reads for Lustre PFL configs
      - PE-38743   - Add ROCM and CUDA information to the mpichversion binary
      - PE-41472   - Clean up lmod module support for CCE 14
      - PE-41476   - Display OFI retry warning properly for SS-11 systems
      - PE-41841   - Change MPICH to work with PMI2's PMI2_keyval_t
      - PE-41861   - MPI_Alltoall optimizations for low PPN counts
      - PE-41968   - Update CXI default values and document software/hybrid endpoint modes
      - PE-42032   - Fix CCE14 lmod MODULEPATH declarations to support cray-hdf5-parallel and cray-parallel-netcdf lmod modules



Product and OS Dependencies:
----------------------------
  The Cray MPICH 8.1.19 release is supported on the following HPE systems:
  * HPE Cray EX systems with CLE
  * HPE Apollo systems as part of the Cray Programming Environment

  Product and OS Dependencies by network type:
  --------------------------------------------------+
                              |       Shasta        |
  ----------------------------+---------------------+
        craype                | >= 2.7.6            |
  ----------------------------+---------------------+
        cray-pals             | >= 1.0.6            |
  ----------------------------+---------------------+
        cray-pmi              | >= 6.0.1            |
  ----------------------------+---------------------+
        libfabric             | >= 1.9.0            |
  ----------------------------+---------------------+

  One or more compilers:
  * AMD ROCM 5.0
  * AOCC 3.0 or later
  * CCE 10.0 or later
  * GNU 9.1 or later
  * Intel 19.0 or later
  * Nvidia 20.7 or later


Notes and Limitations:
----------------------
  Limitations in Cray MPICH 8.1.19:

      - Cray MPICH 8.1.19 can support only ~2040 simultaneous MPI
        communicators.  This limit is less the XC Cray MPICH limit of
        ~4090 simultaneous communicators.  Cray intends to raise the
        limit in a future release of Cray MPICH for Shasta to at least
        the XC limit.


Documentation:
--------------
  For more information see the intro_mpi man page.


Modulefile:
-----------
  module load cray-mpich/8.1.19


License:
--------
  Except for the third party components and software licensed by HPE
  through proprietary agreements, components, files or programs contained
  within this package or product are Copyright -2021 Hewlett Packard
  Enterprise Development LP.

  Attribution notices for open source licensed software for this 
  package are detailed in the file:
  /opt/cray/pe/mpich/8.1.19/ATTRIBUTIONS
=======
Copyright -2022 Hewlett Packard Enterprise Development LP

NetCDF 4.9.0.1
==============

Release Date:
-------------
  September 2022

Purpose:
--------
  This NetCDF release contains the following:
  * Update to upstream release 4.9.0
  * Support for the CCE 14 compiler on Cray XC systems

Product and OS Dependencies:
----------------------------
  The NetCDF release is supported on the following systems:
    * Cray EX systems with CLE 7.0 or later
    * Cray XC systems with CLE 7.0 UP03 and later

  The NetCDF 4.9.0.1 release requires the following software products:

    Cray HDF5 1.12.1.*

    * Cray EX systems:
      CrayPE 2.1.2 or later

      One or more compilers:
        CCE 14.0 or later
        GCC 9.0 or later
        Intel 2021.0 or later
        Nvidia 20.7.0 or later
        AOCC 3.0 or later
        ROCm 4.3 or later

    * Cray XC systems:
      Cray MPT 8.0 or later, or cray-mvapich 2.3.2 or later for A64FX-based systems

      One or more compilers:
        CCE 14.0 or later
        GCC 9.0 or later
        Intel 2021.0 or later
        Nvidia 20.7.0 or later

Notes and Limitations:
----------------------
  For certain F77 source files, when compiling with gcc/10 & gcc/11 & gcc/12, it may be necessary
  to configure/compile with:
      export FCFLAGS="-fallow-argument-mismatch"
      export FFLAGS="-fallow-argument-mismatch"

  This will turn mismatch errors between actual and dummy argument lists to warnings.
  See:
      https://github.com/Unidata/netcdf-fortran/issues/212
      https://gcc.gnu.org/gcc-10/changes.html

  Unidata now packages Netcdf-4 and legacy Netcdf-3 separately. Cray has
  decided not to continue supplying the legacy Netcdf-3 package. Due to CCE
  changes a version of netcdf built with "-sreal64" is neither needed nor
  provided.

  NetCDF is supported on the host CPU but not on the accelerator.

Documentation:
--------------
  http://www.unidata.ucar.edu/software/netcdf/docs

Modulefile:
-----------
  module load cray-netcdf
  OR
  module load cray-netcdf-hdf5parallel

Product description:
--------------------
  NetCDF (network Common Data Form) is a set of interfaces for array-oriented
  data access and a freely-distributed collection of data access libraries for
  C, Fortran, C++, Java, and other languages. The netCDF libraries support a
  machine-independent format for representing scientific data. Together, the
  interfaces, libraries, and format support the creation, access, and sharing
  of scientific data.

Installation:
-------------
 Installation instructions for CLE 7.0 and later:
 ================================================
  rpm -ivh cray-netcdf-4.9.0.1-*202208150326.1387828f2440a-2.sle15.x86_64.rpm
    The "*" in the install command represents compiler version combinations.

  To make this the default version, execute:
    /opt/cray/pe/admin-pe/set_default_files/set_default_netcdf_4.9.0.1

Certain components, files or programs contained within this package or product
are Copyright 2019-2022 Hewlett Packard Enterprise Development LP.

Cray PALS 1.2.2 for PE 22.09:
=============================

Release Date:
-------------
    Sept 2022

Purpose:
--------
    Cray Parallel Application Launch Service (PALS) is an application launcher for
    Cray PE applications.

Key Changes:
------------
    Add support for telling the PMI library the MPI universe size
    Add palsd man page
    Print resource usage of applications
    Lower the maximum CXI AC resources requested to reflect other system needs
    Work around CPE libzmq bug

Documentation:
--------------
    For more information see aprun, mpiexec, palscmd, palsctrl, palsig, and palstat man page.

Modulefile:
-----------
    module load cray-pals

Installation instructions:
--------------------------
    rpm -ihv cray-pals-<version>-<date>.el8.x86_64.rpm
    rpm -ihv cray-palsd-<version>-<date>.el8.x86_64.rpm

Copyright 2022 Hewlett Packard Enterprise Development LP

cray-papi
=================

Release date:
-------------
  September 2022

Purpose:
--------
  New version of papi 6.0.0.16 release 2

Documentation:
--------------
   Overview: https://bitbucket.org/icl/papi
   Web Site: http://icl.utk.edu/papi

Product description:
--------------------
  PAPI aims to provide the tool designer and application engineer with a
  consistent interface and methodology for use of the performance counter
  hardware found in most major microprocessors. PAPI enables software
  engineers to see, in near real time, the relation between software
  performance and processor events.

Dependencies:
-------------
  For a list of software used when validating this version of
  PAPI on Cray and HPE systems, see the HPE Cray Programming
  Environment release announcements.

Copyright 2015-2017,2019-2022 Hewlett Packard Enterprise Development LP


Parallel NetCDF 1.12.3.1
========================

Release Date:
-------------
  September 2022

Purpose:
--------
  This Parallel NetCDF release contains the following:
  * Update to upstream release 1.12.3
  * Support for the CCE 14 compiler on Cray XC systems

  See the Parallel NetCDF documentation for details and usage information.

Product and OS Dependencies:
----------------------------
  This Parallel NetCDF release is supported on on the following systems:
    * Cray EX systems with CLE 7.0 and later
    * Cray XC systems with CLE 7.0 UP03 and later

  The Parallel NetCDF 1.12.3.1 release requires the following software
  products:

    * Cray EX systems:
      CrayPE 2.1.2 or later

      One or more compilers:
        CCE 14.0 or later
        GCC 9.0 or later
        Intel 2021.0 or later
        Nvidia 20.7.0 or later
        AOCC 3.0 or later
        ROCm 4.3 or later

    * Cray XC systems:
      Cray MPT 8.0 or later, or cray-mvapich 2.3.2 or later for A64FX-based systems

      One or more compilers:
        CCE 14.0 or later
        GCC 9.0 or later
        Intel 2021.0 or later
        Nvidia 20.7.0 or later

Notes and Limitations:
----------------------
  For certain F77 source files, when compiling with gcc/10 & gcc/11 & gcc/12, it may be necessary
  to configure/compile with:
      export FCFLAGS="-fallow-argument-mismatch"
      export FFLAGS="-fallow-argument-mismatch"

  This will turn mismatch errors between actual and dummy argument lists to warnings.
  See:
      https://github.com/Unidata/netcdf-fortran/issues/212
      https://gcc.gnu.org/gcc-10/changes.html

Documentation:
--------------
  https://parallel-netcdf.github.io/wiki/Documentation.html

Modulefile:
-----------
  module load cray-parallel-netcdf

Product Description:
--------------------
  Parallel NetCDF is a library providing high-performance I/O while
  maintaining file-format compatibility with Unidata's NetCDF.

Installation:
-------------
 Installation instructions for CLE 7.0 or later:
 ===============================================
  rpm -ivh cray-parallel-netcdf-1.12.3.1-*202208150316.abe5746a10fc0-1.sle15.x86_64.rpm
    The "*" in the install command represents compiler version combinations.

  To make this the default version, execute:
    /opt/cray/pe/admin-pe/set_default_files/set_default_parallel-netcdf_1.12.3.1

Certain components, files or programs contained within this package or product
are Copyright 2019-2022 Hewlett Packard Enterprise Development LP.

Perftools 22.09.0
===============
 Release Date: September 01, 2022

 Purpose:
 ========
   This is a feature and bugfix release for the following systems:
   - HPE Cray EX and HPE Cray Supercomputer Systems with HPCM
   - HPE Cray EX and HPE Cray Supercomputer Systems with CSM
   - HPE Apollo 2000 Gen 10 Plus Systems (x86)
   - HPE Apollo 80 Systems (ARM)
   - HPE Cray XC systems with CLE7 UP03 and CLE7 UP04
   - HPE Cray CS Systems with RH 8

 Key enhancements or changes from the previous release:
 ======================================================
  o Support for AMD ROCm 5.2.0
  o Support for CUDA 11.7.0
  o Support for Intel Sapphire Rapids processors
  o Upgrade to PAPI 6.0.0.16
      - Upstream bugfixes
      - Updated Cassini support
      - Updated Sapphire Rapids events 
  o Added support for host OpenMP Tools (OMPT) callbacks for compilers that support it,
    including Intel icx/ifx, AMD aocc/rocm, and CCE compilers (see the OpenMP section of
    pat_help for more information)
  o Cassini counters without a 'device_' qualifier prepended to the name are now mapped
    to counter groups with the qualifier prepended
  o For pat_report, when -v is specified in conjunction with the option -s tables=list, 
    a column is now added to show whether the -O named in the first column is a table, 
    observation, or observation with table; a column now shows the table title as well
  o Support for CRAY_CUDA_MPS environment variable used to control the CUDA MPS server 
    state on XC systems.  For more detail, see man page: aprun 

 Bugs Fixed:
 ===========
  o Incorrect or missing reporting of certain Nvidia accelerator model information 
  o Limited incompatibilites with CCE 14 
  o Lack of hardware counter collection for Fujitsu A64fx processors

 Important note:
 ===============
    After installing cpe-gcc-11.2.0 or cray-gcc-11.2.0 (or later), all Perftools
    versions prior to Perftools-21.09.0 will fail. There is no workaround for this;
    perftools-21.09.0 later must be used. Cpe-gcc-11.2.0 and cray-gcc-11.2.0 are
    installed as part of the Cray PE-21.09 and later releases.

 Known Issues:
 =============
  o Nvidia released a series of device drivers that do not correctly populate systems files 
    used by Perftools, impacted driver versions: 495.29.05 - 510.60.02.  Reports generated 
    from applications run on devices using impacted drivers will list the accelerator devices 
    as "Unknown". Additionally, usage of accelerator performance counter groups is not 
    supported for experiments run on devices using impacted drivers.
  o ROCm 5.2.0 introduced API changes that prevent backwards compatibility with previous
    Perftools versions.

 Dependencies:
 =============
  o A PDF reader (evince, acroread or okular) is required to use the 
    app2 online help.
  o For a list of software used when validating this version of 
    Perftools on Cray and HPE systems, see the HPE Cray Programming Environment
    release announcements.

 Installation instructions:
 ==========================
 For XC systems, please see the XC Series Software Installation and 
 Configuration Guide (S-2559).

 For CS systems, please see the CS System Programming Environments 
 Installation Guide (S-2800).

 For Apollo 80 systems, please see the HPE Cray Programming Environments
 Installation Guide: Apollo 80 (ARM) System (S-8013).

 For Apollo 2000 systems, please see the HPE Cray Programming Environments
 Installation Guide: Apollo 2000 Gen10 Plus (x86) System (S-8012).

 For HPE Cray EX (Shasta Architecture) systems, refer to the Cray Asynchronous 
 Installer Guide (S-8003).

 Installation of app2 remote client (+ server) on Mac systems:
 -------------------------------------------------------------
 Apprentice2Installer-22.09.0.dmg
 RevealInstaller-22.09.0.dmg

 The Cray Apprentice2 and Reveal installers for Mac are included in the
 perftools-clients rpm, and placed in

 $CRAYPAT_ROOT/share/desktop_installers/

 on a Cray Shasta User Access Node (UAN) or on a Cray login node when the 
 perftools software is installed.


 Download the Cray Apprentice2 installer onto a desktop or laptop
 running Mac OS El Capitan through Mojave. Double click on installer 
 to begin installation.  The installer will walk you through the 
 process for your system.

 Installation of app2 remote client (+ server) on Windows 10 systems:
 --------------------------------------------------------------------
 Apprentice2Installer-22.09.0.exe

 The Cray Apprentice2 installer for Windows is included in the
 perftools-clients rpm, and placed in
 
 $CRAYPAT_ROOT/share/desktop_installers/

 on a Cray Shasta User Access Node (UAN) or on a Cray login node when the 
 perftools software is installed.
 Download the Cray Apprentice2 installer onto a desktop or laptop
 running Windows 10. Double click on installer to begin installation.
 The installer will walk you through the process for your system.

 Documentation:
 ==============
 See the following man pages:
   intro_craypat, pat_build, pat_help, pat_info, pat_report, pat_run, pat_view
   grid_order, pat_opts

   reveal, app2

   perftools-base, perftools-lite, perftools-preload

   hwpc, nwpc, accpc, uncore, cray_pm, papi_counters

 Search for perftools on https://support.hpe.com to access documentation
 on Cray Performance Measurement and Analysis Tools

 License:
 ========
 Except for the third party modules discussed below and software licensed
 by HPE through proprietary agreements, components, files or programs
 contained within this package or product are Copyright 2001-2022
 Hewlett Packard Enterprise Development LP.

 Attribution notices for open source licensed software contained in this
 package are detailed in the file:
 $CRAYPAT_ROOT/ATTRIBUTIONS_perftools.txt

Cray PMI 6.1.5
==============================================================================

Release Date:
--------------
  August 15, 2022


Purpose:
--------
  The Cray Process Manager Interface Library provides the interface between the
  application launcher and other communication libraries such as MPICH and SHMEM.

  Cray PMI 6.1.5 is optimized for the Cray Programming Environment.

  New Cray PMI features for HPE Cray EX and Apollo systems:


Key Changes and Bugs Closed:
----------------------------
  Starting with Cray-PMI 6.1.0 the cray-pmi and cray-pmi-lib modules have been
  combined into a single cray-pmi module.  The cray-pmi-lib module will no longer
  be installed by new cray-pmi rpms.  When the cray-pmi module is loaded, the
  pmi libraries will be linked with as-needed flags.  To assist with the
  transition, an earlier version of Cray-PMI will be provided non-default for
  several releases.  This will provide time for any script referencing the
  cray-pmi-lib module to be modified without immediately breaking.
 

  Bug fixes new to Cray PMI 6.1.5 include:

      - CAST-30385 - Change PMI_IFACE to support not using any suffix
      - PE-41850 - Enable Spawn API to work on Slurm

Product and OS Dependencies:
----------------------------
  The Cray PMI 6.1.5 release is supported on the following systems:
  * HPE Cray EX systems with CLE
  * HPE Apollo systems as part of the Cray Programming Environment

  Product Dependencies:
  ----------------------------------------+
        cray-pals        | >= 1.0.6       |
  -----------------------+----------------+
        slurm            | >= 20.02       |
  -----------------------+----------------+


Notes and Limitations:
----------------------


Documentation:
--------------
  For more information see the intro_pmi man page.


Modulefile:
-----------
  module load cray-pmi/6.1.5


License:
--------
  Except for the third party components and software licensed by HPE
  through proprietary agreements, components, files or programs contained
  within this package or product are Copyright 2020-2021 Hewlett Packard
  Enterprise Development LP.

  Attribution notices for open source licensed software for this 
  package are detailed in the file:
  /opt/cray/pe/pmi/6.1.5/ATTRIBUTIONS

cray-python 3.9.13.1
====================

Release Date
------------
September 2022

Purpose
-------
Cray Python is an implementation of the Python programming language for the Cray
Programming Environment. The numpy and scipy modules are configured to call Cray
Libsci routines. The mpi4py module is configured to call Cray MPICH routines.
Cray Python is designed to run Python codes on the compute nodes of an HPE
supercomputer. HPE does not make changes to the Python source or any of its
libraries nor does it plan to make changes in future releases.

The cray-python 3.9.13.1 release contains

    python  3.9.13
    numpy   1.21.5
    scipy   1.6.2
    mpi4py  3.1.3
    dask    2022.2.1

Product and OS Dependencies
---------------------------
The cray-python 3.9.13.1 release is supported on
- Cray EX systems running SLES 15 or RHEL 8
- Cray XC systems running SLES 15

Documentation
-------------
https://www.python.org/doc

Changelog
---------
https://docs.python.org/release/3.9.13/whatsnew/changelog.html

Modulefile
----------
    module load cray-python/3.9.13.1

Installation
------------
    rpm -ihv cray-python-3.9.13.1-202207292200_5a2fb49-1.sles15.x86_64.rpm

To make this the default version, execute

    /opt/cray/pe/admin-pe/set_default_files/set_default_python_3.9.13.1

Certain components, files, or programs contained within this package are  
© Copyright 2021-2022 Hewlett Packard Enterprise Development LP

cray-R 4.2.1.1
============

Release Date:
-------------
September 2022

Purpose:
--------
The cray-R 4.2.1.1 release.
cray-R is configured to call cray-libsci routines.

Product and OS Dependencies:
----------------------------
The cray-R 4.2.1.1 release is supported on
- Cray EX systems running
- Cray XC systems running CLE 7.0 or later operating systems

Documentation:
--------------
https://cran.r-project.org/manuals.html

Modulefile:
---------------------
module load cray-R/4.2.1.1

Installation:
-------------
rpm -ihv cray-R-4.2.1.1-202208051920.1cdb6df582cdf-2.shasta.x86_64.rpm

To make this the default version, execute:
  /opt/cray/pe/admin-pe/set_default_files/set_default_R_4.2.1.1

Certain components, files or programs contained within this package or product are
Copyright 2018-2022 Hewlett Packard Enterprise Development LP

